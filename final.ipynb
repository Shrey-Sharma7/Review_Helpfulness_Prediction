{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataCleaning import *\n",
    "from dataPreprocessing import *\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline   \n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataCleaning('./CSV/iphone_dataset.csv')\n",
    "mydf = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.drop(mydf[(mydf['review_helpful_vote'] == 0) & (mydf['review_text'].apply(lambda x:len(x.split())) < 10)].index,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating = mydf['review_rating'].mean()\n",
    "mydf['rating_diff'] = abs(mydf['review_rating'] - avg_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>VADER</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['scores'] = mydf['review_text'].apply(lambda review:vds.polarity_scores(review))\n",
    "mydf['compound'] = mydf['scores'].apply(lambda x:x['compound'])\n",
    "mydf['vader_score'] = mydf['compound'].apply(lambda x:1 if x >= 0  else 0)\n",
    "mydf = mydf.drop(['scores','compound'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Average Word length</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "mydf['avg_word_length'] = mydf['review_text'].apply(lambda x:avg_word(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>No. of Stop Words</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "mydf['stopwords_count'] = mydf['review_text'].apply(lambda x:len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>No. of Uppercase Words</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['upper'] = mydf['review_text'].apply(lambda x:len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Data Preprocessing</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = dataPreprocessing(mydf)\n",
    "def categorize(row):\n",
    "    if row['review_helpful_vote'] == 0:\n",
    "        return 0\n",
    "    elif row['review_helpful_vote'] > 0 and row['review_helpful_vote'] <= 5:\n",
    "        return 1\n",
    "    elif row['review_helpful_vote'] > 5:\n",
    "        return 2\n",
    "\n",
    "\n",
    "mydf['helpfulness'] = mydf.apply(lambda row :categorize(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_helpful_vote</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>upper</th>\n",
       "      <th>review</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>helpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5087</td>\n",
       "      <td>1.102387</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>note</td>\n",
       "      <td>[note]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.102387</td>\n",
       "      <td>0</td>\n",
       "      <td>4.952381</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>very bad experience with this iphone xr phone ...</td>\n",
       "      <td>[bad, experience, iphone, xr, phone, back, cam...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>1</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>amazing phone with amazing camera coming from ...</td>\n",
       "      <td>[amazing, phone, amazing, camera, coming, ipho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "      <td>3.102387</td>\n",
       "      <td>1</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>so i got the iphone xr just today  the product...</td>\n",
       "      <td>[got, iphone, xr, today, product, look, amazin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>536</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>1</td>\n",
       "      <td>4.063291</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>i have been an android user all my life until ...</td>\n",
       "      <td>[android, user, life, decided, try, iphone, xr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_rating  review_helpful_vote  rating_diff  vader_score  \\\n",
       "0              3                 5087     1.102387            1   \n",
       "1              1                 2822     3.102387            0   \n",
       "2              5                 1798     0.897613            1   \n",
       "3              1                 1366     3.102387            1   \n",
       "4              5                  536     0.897613            1   \n",
       "\n",
       "   avg_word_length  stopwords_count  upper  \\\n",
       "0         5.000000                0      1   \n",
       "1         4.952381               16      2   \n",
       "2         5.142857                3      0   \n",
       "3         4.800000               56      4   \n",
       "4         4.063291               30      4   \n",
       "\n",
       "                                              review  \\\n",
       "0                                              note    \n",
       "1  very bad experience with this iphone xr phone ...   \n",
       "2  amazing phone with amazing camera coming from ...   \n",
       "3  so i got the iphone xr just today  the product...   \n",
       "4  i have been an android user all my life until ...   \n",
       "\n",
       "                                          lemmatized  helpfulness  \n",
       "0                                             [note]            2  \n",
       "1  [bad, experience, iphone, xr, phone, back, cam...            2  \n",
       "2  [amazing, phone, amazing, camera, coming, ipho...            2  \n",
       "3  [got, iphone, xr, today, product, look, amazin...            2  \n",
       "4  [android, user, life, decided, try, iphone, xr...            2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf['review_helpful_vote'].value_counts()\n",
    "mydf.head()\n",
    "# tempdf = mydf['review_helpful_vote', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mydf[['lemmatized','vader_score','rating_diff','stopwords_count','avg_word_length']]\n",
    "y = mydf['helpfulness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_merged = X_train.merge(pd.DataFrame(X_train_vect_avg, index = X_train.index), right_index = True, left_index = True)\n",
    "# X_test_merged = X_test.merge(pd.DataFrame(X_test_vect_avg, index = X_test.index), right_index = True, left_index = True)\n",
    "# X_train_final = X_train_merged.drop('lemmatized', axis =1)\n",
    "# X_test_final = X_test_merged.drop('lemmatized', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\felix_env\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\Users\\hp\\anaconda3\\envs\\felix_env\\lib\\site-packages\\ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(X_train['lemmatized'], vector_size=100, window=5, min_count=2,sg=1)\n",
    "words = set(model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([model.wv[i] for i in ls if i in words]) for ls in X_train.lemmatized])\n",
    "X_test_vect = np.array([np.array([model.wv[i] for i in ls if i in words]) for ls in X_test.lemmatized])\n",
    "\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100,dtype=float))\n",
    "\n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100,dtype=float))\n",
    "\n",
    "# X_train_merged = X.merge(pd.DataFrame(X_train_vect_avg, index = X.index), right_index = True, left_index = True)\n",
    "# X_train_final = X_train_merged.drop('lemmatized', axis =1)\n",
    "X_train_merged = X_train.merge(pd.DataFrame(X_train_vect_avg, index = X_train.index), right_index = True, left_index = True)\n",
    "X_test_merged = X_test.merge(pd.DataFrame(X_test_vect_avg, index = X_test.index), right_index = True, left_index = True)\n",
    "X_train_final = X_train_merged.drop('lemmatized', axis =1)\n",
    "X_test_final = X_test_merged.drop('lemmatized', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_score</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>3</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>-0.127899</td>\n",
       "      <td>0.257563</td>\n",
       "      <td>-0.013530</td>\n",
       "      <td>-0.093427</td>\n",
       "      <td>0.072138</td>\n",
       "      <td>-0.250549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255343</td>\n",
       "      <td>0.125192</td>\n",
       "      <td>0.085901</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.310131</td>\n",
       "      <td>0.147246</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>-0.093880</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>-0.045240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>2</td>\n",
       "      <td>3.303030</td>\n",
       "      <td>-0.144607</td>\n",
       "      <td>0.276041</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>-0.060245</td>\n",
       "      <td>0.070993</td>\n",
       "      <td>-0.253433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254593</td>\n",
       "      <td>0.089863</td>\n",
       "      <td>0.043169</td>\n",
       "      <td>0.015506</td>\n",
       "      <td>0.288576</td>\n",
       "      <td>0.159818</td>\n",
       "      <td>-0.021959</td>\n",
       "      <td>-0.126666</td>\n",
       "      <td>0.053404</td>\n",
       "      <td>-0.025929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>7</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>-0.132909</td>\n",
       "      <td>0.271432</td>\n",
       "      <td>-0.013383</td>\n",
       "      <td>-0.093031</td>\n",
       "      <td>0.070974</td>\n",
       "      <td>-0.253801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260344</td>\n",
       "      <td>0.108958</td>\n",
       "      <td>0.090662</td>\n",
       "      <td>0.015894</td>\n",
       "      <td>0.306795</td>\n",
       "      <td>0.141915</td>\n",
       "      <td>-0.015620</td>\n",
       "      <td>-0.090366</td>\n",
       "      <td>0.044041</td>\n",
       "      <td>-0.039113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>21</td>\n",
       "      <td>4.510204</td>\n",
       "      <td>-0.143999</td>\n",
       "      <td>0.257285</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>-0.057865</td>\n",
       "      <td>0.064854</td>\n",
       "      <td>-0.239838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246970</td>\n",
       "      <td>0.063350</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.259435</td>\n",
       "      <td>0.151857</td>\n",
       "      <td>-0.019188</td>\n",
       "      <td>-0.132066</td>\n",
       "      <td>0.048002</td>\n",
       "      <td>-0.027288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.184483</td>\n",
       "      <td>0.261519</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>0.072306</td>\n",
       "      <td>-0.247223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268914</td>\n",
       "      <td>0.070894</td>\n",
       "      <td>0.042843</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.267106</td>\n",
       "      <td>0.180839</td>\n",
       "      <td>-0.025567</td>\n",
       "      <td>-0.161607</td>\n",
       "      <td>0.043461</td>\n",
       "      <td>-0.022725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>0</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>3</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-0.104514</td>\n",
       "      <td>0.245758</td>\n",
       "      <td>-0.052649</td>\n",
       "      <td>-0.154827</td>\n",
       "      <td>0.078687</td>\n",
       "      <td>-0.253674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270211</td>\n",
       "      <td>0.179193</td>\n",
       "      <td>0.203938</td>\n",
       "      <td>0.051176</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.119881</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>-0.031759</td>\n",
       "      <td>0.027508</td>\n",
       "      <td>-0.064530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>5</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>-0.151888</td>\n",
       "      <td>0.262793</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>-0.031281</td>\n",
       "      <td>0.070935</td>\n",
       "      <td>-0.242325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251608</td>\n",
       "      <td>0.058651</td>\n",
       "      <td>-0.026401</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.240862</td>\n",
       "      <td>0.158772</td>\n",
       "      <td>-0.008887</td>\n",
       "      <td>-0.161411</td>\n",
       "      <td>0.067566</td>\n",
       "      <td>-0.017373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>9</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>-0.133241</td>\n",
       "      <td>0.270361</td>\n",
       "      <td>-0.023627</td>\n",
       "      <td>-0.094761</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>-0.253885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255575</td>\n",
       "      <td>0.126613</td>\n",
       "      <td>0.112680</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>0.315636</td>\n",
       "      <td>0.141618</td>\n",
       "      <td>-0.014338</td>\n",
       "      <td>-0.077782</td>\n",
       "      <td>0.033263</td>\n",
       "      <td>-0.044082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>3</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>-0.154497</td>\n",
       "      <td>0.308364</td>\n",
       "      <td>0.060991</td>\n",
       "      <td>-0.011783</td>\n",
       "      <td>0.080398</td>\n",
       "      <td>-0.260235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259307</td>\n",
       "      <td>0.059446</td>\n",
       "      <td>-0.097181</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.235433</td>\n",
       "      <td>0.169974</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.182414</td>\n",
       "      <td>0.094649</td>\n",
       "      <td>-0.032204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>1</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>2</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>-0.114768</td>\n",
       "      <td>0.218952</td>\n",
       "      <td>-0.038142</td>\n",
       "      <td>-0.129900</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>-0.233149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267584</td>\n",
       "      <td>0.160863</td>\n",
       "      <td>0.183068</td>\n",
       "      <td>0.053903</td>\n",
       "      <td>0.352335</td>\n",
       "      <td>0.133661</td>\n",
       "      <td>0.015657</td>\n",
       "      <td>-0.046731</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>-0.061464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2228 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vader_score  rating_diff  stopwords_count  avg_word_length         0  \\\n",
       "943             1     0.897613                3         5.900000 -0.127899   \n",
       "5087            1     0.897613                2         3.303030 -0.144607   \n",
       "6407            1     0.897613                7         4.720000 -0.132909   \n",
       "5920            1     0.897613               21         4.510204 -0.143999   \n",
       "2610            1     0.897613                0         4.000000 -0.184483   \n",
       "...           ...          ...              ...              ...       ...   \n",
       "3317            0     0.897613                3         3.700000 -0.104514   \n",
       "6223            1     0.897613                5         4.750000 -0.151888   \n",
       "5321            1     0.897613                9         4.714286 -0.133241   \n",
       "5266            1     0.897613                3         3.571429 -0.154497   \n",
       "2107            1     0.897613                2         4.500000 -0.114768   \n",
       "\n",
       "             1         2         3         4         5  ...        90  \\\n",
       "943   0.257563 -0.013530 -0.093427  0.072138 -0.250549  ...  0.255343   \n",
       "5087  0.276041  0.004978 -0.060245  0.070993 -0.253433  ...  0.254593   \n",
       "6407  0.271432 -0.013383 -0.093031  0.070974 -0.253801  ...  0.260344   \n",
       "5920  0.257285  0.002420 -0.057865  0.064854 -0.239838  ...  0.246970   \n",
       "2610  0.261519  0.022993 -0.044318  0.072306 -0.247223  ...  0.268914   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "3317  0.245758 -0.052649 -0.154827  0.078687 -0.253674  ...  0.270211   \n",
       "6223  0.262793  0.015330 -0.031281  0.070935 -0.242325  ...  0.251608   \n",
       "5321  0.270361 -0.023627 -0.094761  0.078375 -0.253885  ...  0.255575   \n",
       "5266  0.308364  0.060991 -0.011783  0.080398 -0.260235  ...  0.259307   \n",
       "2107  0.218952 -0.038142 -0.129900  0.097548 -0.233149  ...  0.267584   \n",
       "\n",
       "            91        92        93        94        95        96        97  \\\n",
       "943   0.125192  0.085901  0.016735  0.310131  0.147246 -0.001028 -0.093880   \n",
       "5087  0.089863  0.043169  0.015506  0.288576  0.159818 -0.021959 -0.126666   \n",
       "6407  0.108958  0.090662  0.015894  0.306795  0.141915 -0.015620 -0.090366   \n",
       "5920  0.063350  0.034148  0.008477  0.259435  0.151857 -0.019188 -0.132066   \n",
       "2610  0.070894  0.042843  0.023537  0.267106  0.180839 -0.025567 -0.161607   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3317  0.179193  0.203938  0.051176  0.378238  0.119881  0.005443 -0.031759   \n",
       "6223  0.058651 -0.026401  0.001459  0.240862  0.158772 -0.008887 -0.161411   \n",
       "5321  0.126613  0.112680  0.021104  0.315636  0.141618 -0.014338 -0.077782   \n",
       "5266  0.059446 -0.097181  0.001696  0.235433  0.169974 -0.000322 -0.182414   \n",
       "2107  0.160863  0.183068  0.053903  0.352335  0.133661  0.015657 -0.046731   \n",
       "\n",
       "            98        99  \n",
       "943   0.054205 -0.045240  \n",
       "5087  0.053404 -0.025929  \n",
       "6407  0.044041 -0.039113  \n",
       "5920  0.048002 -0.027288  \n",
       "2610  0.043461 -0.022725  \n",
       "...        ...       ...  \n",
       "3317  0.027508 -0.064530  \n",
       "6223  0.067566 -0.017373  \n",
       "5321  0.033263 -0.044082  \n",
       "5266  0.094649 -0.032204  \n",
       "2107  0.015729 -0.061464  \n",
       "\n",
       "[2228 rows x 104 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>GridSearch CV</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(probability=True, random_state=42)\n",
    "clf2 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param1 = {}\n",
    "param1['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param1['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "param1['classifier'] = [clf1]\n",
    "\n",
    "param2 = {}\n",
    "param2['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "param2['classifier__max_depth'] = [5, 10, 20]\n",
    "param2['classifier'] = [clf2]\n",
    "\n",
    "pipeline = Pipeline([('classifier', clf1)])\n",
    "params = [param1, param2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline, params, cv=3, n_jobs=-1, scoring='accuracy').fit(X_train_final.values,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': SVC(C=10, probability=True, random_state=42),\n",
       " 'classifier__C': 10,\n",
       " 'classifier__class_weight': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6992843659721945"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Stacking Ensemble Model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking Models used\n",
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression()))\n",
    "level0.append(('svm', SVC()))\n",
    "level0.append(('xgb',XGBClassifier()))\n",
    "level0.append(('gdb',GradientBoostingClassifier()))\n",
    "level1 = LogisticRegression()\n",
    "\n",
    "# define the stacking ensemble\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model,X_train_final.values,y_train,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6912047160779966"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('felix_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b119379096f2206da1c84684532044256fec83c3d2ecb93cf1210f321cca8775"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
