{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataCleaning import *\n",
    "from dataPreprocessing import *\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline   \n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataCleaning('./CSV/iphone_dataset.csv')\n",
    "mydf = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.drop(mydf[(mydf['review_helpful_vote'] == 0) & (mydf['review_text'].apply(lambda x:len(x.split())) < 10)].index,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating = mydf['review_rating'].mean()\n",
    "mydf['rating_diff'] = abs(mydf['review_rating'] - avg_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>VADER</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['scores'] = mydf['review_text'].apply(lambda review:vds.polarity_scores(review))\n",
    "mydf['compound'] = mydf['scores'].apply(lambda x:x['compound'])\n",
    "mydf['vader_score'] = mydf['compound'].apply(lambda x:1 if x >= 0  else 0)\n",
    "mydf = mydf.drop(['scores','compound'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Average Word length</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "mydf['avg_word_length'] = mydf['review_text'].apply(lambda x:avg_word(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>No. of Stop Words</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "mydf['stopwords_count'] = mydf['review_text'].apply(lambda x:len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>No. of Uppercase Words</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['upper'] = mydf['review_text'].apply(lambda x:len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Data Preprocessing</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = dataPreprocessing(mydf)\n",
    "def categorize(row):\n",
    "    if row['review_helpful_vote'] == 0:\n",
    "        return 0\n",
    "    elif row['review_helpful_vote'] > 0 and row['review_helpful_vote'] <= 5:\n",
    "        return 1\n",
    "    elif row['review_helpful_vote'] > 5:\n",
    "        return 2\n",
    "\n",
    "\n",
    "mydf['helpfulness'] = mydf.apply(lambda row :categorize(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_helpful_vote</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>vader_score</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>upper</th>\n",
       "      <th>review</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>helpfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5087</td>\n",
       "      <td>1.102387</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>note</td>\n",
       "      <td>[note]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2822</td>\n",
       "      <td>3.102387</td>\n",
       "      <td>0</td>\n",
       "      <td>4.952381</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>very bad experience with this iphone xr phone ...</td>\n",
       "      <td>[bad, experience, iphone, xr, phone, back, cam...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1798</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>1</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>amazing phone with amazing camera coming from ...</td>\n",
       "      <td>[amazing, phone, amazing, camera, coming, ipho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1366</td>\n",
       "      <td>3.102387</td>\n",
       "      <td>1</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>so i got the iphone xr just today  the product...</td>\n",
       "      <td>[got, iphone, xr, today, product, look, amazin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>536</td>\n",
       "      <td>0.897613</td>\n",
       "      <td>1</td>\n",
       "      <td>4.063291</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>i have been an android user all my life until ...</td>\n",
       "      <td>[android, user, life, decided, try, iphone, xr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_rating  review_helpful_vote  rating_diff  vader_score  \\\n",
       "0              3                 5087     1.102387            1   \n",
       "1              1                 2822     3.102387            0   \n",
       "2              5                 1798     0.897613            1   \n",
       "3              1                 1366     3.102387            1   \n",
       "4              5                  536     0.897613            1   \n",
       "\n",
       "   avg_word_length  stopwords_count  upper  \\\n",
       "0         5.000000                0      1   \n",
       "1         4.952381               16      2   \n",
       "2         5.142857                3      0   \n",
       "3         4.800000               56      4   \n",
       "4         4.063291               30      4   \n",
       "\n",
       "                                              review  \\\n",
       "0                                              note    \n",
       "1  very bad experience with this iphone xr phone ...   \n",
       "2  amazing phone with amazing camera coming from ...   \n",
       "3  so i got the iphone xr just today  the product...   \n",
       "4  i have been an android user all my life until ...   \n",
       "\n",
       "                                          lemmatized  helpfulness  \n",
       "0                                             [note]            2  \n",
       "1  [bad, experience, iphone, xr, phone, back, cam...            2  \n",
       "2  [amazing, phone, amazing, camera, coming, ipho...            2  \n",
       "3  [got, iphone, xr, today, product, look, amazin...            2  \n",
       "4  [android, user, life, decided, try, iphone, xr...            2  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf['review_helpful_vote'].value_counts()\n",
    "mydf.head()\n",
    "# tempdf = mydf['review_helpful_vote', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mydf[['lemmatized','vader_score','rating_diff','stopwords_count','avg_word_length']]\n",
    "X1 = mydf[['lemmatized','vader_score']]\n",
    "X2 = mydf[['vader_score','rating_diff','stopwords_count','avg_word_length']]\n",
    "\n",
    "y = mydf['helpfulness']\n",
    "y1 = mydf['helpfulness']\n",
    "y2 = mydf['helpfulness']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)\n",
    "X1_train,X1_test,y1_train, y1_test = train_test_split(X1,y1,test_size = 0.3)\n",
    "X2_train,X2_test,y2_train,y2_test = train_test_split(X2,y2,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_merged = X_train.merge(pd.DataFrame(X_train_vect_avg, index = X_train.index), right_index = True, left_index = True)\n",
    "# X_test_merged = X_test.merge(pd.DataFrame(X_test_vect_avg, index = X_test.index), right_index = True, left_index = True)\n",
    "# X_train_final = X_train_merged.drop('lemmatized', axis =1)\n",
    "# X_test_final = X_test_merged.drop('lemmatized', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(X_train['lemmatized'], vector_size=100, window=5, min_count=2,sg=1)\n",
    "words = set(model.wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([model.wv[i] for i in ls if i in words]) for ls in X_train.lemmatized])\n",
    "X_test_vect = np.array([np.array([model.wv[i] for i in ls if i in words]) for ls in X_test.lemmatized])\n",
    "\n",
    "X_train_vect_avg = []\n",
    "for v in X_train_vect:\n",
    "    if v.size:\n",
    "        X_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_train_vect_avg.append(np.zeros(100,dtype=float))\n",
    "\n",
    "X_test_vect_avg = []\n",
    "for v in X_test_vect:\n",
    "    if v.size:\n",
    "        X_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X_test_vect_avg.append(np.zeros(100,dtype=float))\n",
    "\n",
    "# X_train_merged = X.merge(pd.DataFrame(X_train_vect_avg, index = X.index), right_index = True, left_index = True)\n",
    "# X_train_final = X_train_merged.drop('lemmatized', axis =1)\n",
    "X_train_merged = X_train.merge(pd.DataFrame(X_train_vect_avg, index = X_train.index), right_index = True, left_index = True)\n",
    "X_test_merged = X_test.merge(pd.DataFrame(X_test_vect_avg, index = X_test.index), right_index = True, left_index = True)\n",
    "X_train_final = X_train_merged.drop('lemmatized', axis =1)\n",
    "X_test_final = X_test_merged.drop('lemmatized', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Word2Vec(X1_train['lemmatized'], vector_size=100, window=5, min_count=2,sg=1)\n",
    "words1 = set(model.wv.index_to_key)\n",
    "X1_train_vect = np.array([np.array([model.wv[i] for i in ls if i in words]) for ls in X1_train.lemmatized])\n",
    "X1_test_vect = np.array([np.array([model.wv[i] for i in ls if i in words]) for ls in X1_test.lemmatized])\n",
    "\n",
    "X1_train_vect_avg = []\n",
    "for v in X1_train_vect:\n",
    "    if v.size:\n",
    "        X1_train_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X1_train_vect_avg.append(np.zeros(100,dtype=float))\n",
    "\n",
    "X1_test_vect_avg = []\n",
    "for v in X1_test_vect:\n",
    "    if v.size:\n",
    "        X1_test_vect_avg.append(v.mean(axis=0))\n",
    "    else:\n",
    "        X1_test_vect_avg.append(np.zeros(100,dtype=float))\n",
    "\n",
    "# X_train_merged = X.merge(pd.DataFrame(X_train_vect_avg, index = X.index), right_index = True, left_index = True)\n",
    "# X_train_final = X_train_merged.drop('lemmatized', axis =1)\n",
    "X1_train_merged = X1_train.merge(pd.DataFrame(X1_train_vect_avg, index = X1_train.index), right_index = True, left_index = True)\n",
    "X1_test_merged = X1_test.merge(pd.DataFrame(X1_test_vect_avg, index = X1_test.index), right_index = True, left_index = True)\n",
    "X1_train_final = X1_train_merged.drop('lemmatized', axis =1)\n",
    "X1_test_final = X1_test_merged.drop('lemmatized', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>GridSearch CV</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf1 = SVC(probability=True, random_state=42)\n",
    "# clf2 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# param1 = {}\n",
    "# param1['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "# param1['classifier__class_weight'] = [None, {0:1,1:5}, {0:1,1:10}, {0:1,1:25}]\n",
    "# param1['classifier'] = [clf1]\n",
    "\n",
    "# param2 = {}\n",
    "# param2['classifier__n_estimators'] = [10, 50, 100, 250]\n",
    "# param2['classifier__max_depth'] = [5, 10, 20]\n",
    "# param2['classifier'] = [clf2]\n",
    "\n",
    "# pipeline = Pipeline([('classifier', clf1)])\n",
    "# params = [param1, param2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs = GridSearchCV(pipeline, params, cv=3, n_jobs=-1, scoring='accuracy').fit(X_train_final.values,y_train)\n",
    "# gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state =42)\n",
    "lr_model = lr.fit(X_train_final.values,y_train)\n",
    "lr_pred = lr_model.predict(X_test_final.values)\n",
    "print(accuracy_score(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.602510460251046\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state =42)\n",
    "lr1_model = lr.fit(X1_train_final.values,y1_train)\n",
    "lr1_pred = lr1_model.predict(X1_test_final.values)\n",
    "print(accuracy_score(y1_test,lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6244769874476988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\felix_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state =42)\n",
    "lr2_model = lr.fit(X2_train.values,y2_train)\n",
    "lr2_pred = lr2_model.predict(X2_test.values)\n",
    "print(accuracy_score(y2_test,lr2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6882845188284519\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state = 42)\n",
    "svc_model = svc.fit(X_train_final.values,y_train)\n",
    "svc_pred = svc_model.predict(X_test_final.values)\n",
    "print(accuracy_score(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5930962343096234\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state = 42)\n",
    "svc1_model = svc.fit(X1_train_final.values,y1_train)\n",
    "svc1_pred = svc1_model.predict(X1_test_final.values)\n",
    "print(accuracy_score(y1_test,svc1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6914225941422594\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state = 42)\n",
    "svc2_model = svc.fit(X2_train.values,y2_train)\n",
    "svc2_pred = svc2_model.predict(X2_test.values)\n",
    "print(accuracy_score(y2_test,svc2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.643305439330544\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_model = knn.fit(X_train_final.values,y_train)\n",
    "knn_pred = knn_model.predict(X_test_final.values)\n",
    "print(accuracy_score(y_test,knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5889121338912134\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn1_model = knn.fit(X1_train_final.values,y1_train)\n",
    "knn1_pred = knn1_model.predict(X1_test_final.values)\n",
    "print(accuracy_score(y1_test,knn1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier()\n",
    "# knn2_model = knn.fit(X2_train.values,y2_train)\n",
    "# knn2_pred = knn_model.predict(X2_test.values)\n",
    "# print(accuracy_score(y2_test,knn2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5993723849372385\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "dtc_model = dtc.fit(X_train_final.values,y_train)\n",
    "dtc_pred = dtc_model.predict(X_test_final.values)\n",
    "print(accuracy_score(y_test,dtc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5209205020920502\n"
     ]
    }
   ],
   "source": [
    "dtc1 = DecisionTreeClassifier(random_state = 42)\n",
    "dtc1_model = dtc.fit(X1_train_final.values,y1_train)\n",
    "dtc1_pred = dtc_model.predict(X1_test_final.values)\n",
    "print(accuracy_score(y1_test,dtc1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6119246861924686\n"
     ]
    }
   ],
   "source": [
    "dtc2 = DecisionTreeClassifier(random_state = 42)\n",
    "dtc2_model = dtc.fit(X2_train.values,y2_train)\n",
    "dtc2_pred = dtc2_model.predict(X2_test.values)\n",
    "print(accuracy_score(y2_test,dtc2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking Models used\n",
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression()))\n",
    "level0.append(('svm', SVC()))\n",
    "level0.append(('knn',KNeighborsClassifier()))\n",
    "level0.append(('dtc',DecisionTreeClassifier()))\n",
    "level1 = SVC()\n",
    "\n",
    "# define the stacking ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6768418400765859"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StackingClassifier(estimators=level0, final_estimator=level1,cv=5)\n",
    "scores = cross_val_score(model,X_train_final.values,y_train,n_jobs=-1,scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6009825162493072"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = StackingClassifier(estimators=level0, final_estimator=level1,cv=5)\n",
    "scores1 = cross_val_score(model,X1_train_final.values,y1_train,n_jobs=-1,scoring='accuracy')\n",
    "scores1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6714586587393561"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = StackingClassifier(estimators=level0, final_estimator=level1,cv=5)\n",
    "scores2 = cross_val_score(model,X2_train.values,y2_train,n_jobs=-1,scoring='accuracy')\n",
    "scores2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('felix_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b119379096f2206da1c84684532044256fec83c3d2ecb93cf1210f321cca8775"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
